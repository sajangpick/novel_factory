"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
[RAG Engine] ë¬´ë¦¼ ì„¸ê³„ê´€ ê²€ìƒ‰ ì—”ì§„
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

novels/murim_mna/world_db/*.md íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ê³  ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ê²€ìƒ‰ ëª¨ë“œ:
1. í‚¤ì›Œë“œ ê²€ìƒ‰ (ê¸°ë³¸) - í•­ìƒ ë™ì‘, ì™¸ë¶€ API ë¶ˆí•„ìš”
2. ì‹œë§¨í‹± ê²€ìƒ‰ (ì„ íƒ) - OpenAI Embeddings API í•„ìš”

ì‚¬ìš© ì˜ˆì‹œ:
  engine = RAGEngine("../novels/murim_mna/world_db")
  results = engine.search("í™”ì‚°íŒŒ ìœ„ì¹˜", top_k=5)
"""

import os
import re
from pathlib import Path
from typing import Optional


class Document:
    """ì„¸ê³„ê´€ ë¬¸ì„œ í•˜ë‚˜ë¥¼ ë‚˜íƒ€ë‚´ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, name: str, category: str, content: str, path: str):
        self.name = name           # íŒŒì¼ëª… (í™•ì¥ì ì œì™¸)
        self.category = category   # ì¹´í…Œê³ ë¦¬ (íŒŒì¼ëª…ì—ì„œ ì¶”ë¡ )
        self.content = content     # ì „ì²´ í…ìŠ¤íŠ¸
        self.path = path           # íŒŒì¼ ê²½ë¡œ
        self.chunks: list[dict] = []  # ë¶„í• ëœ ì²­í¬ë“¤


class Chunk:
    """ë¬¸ì„œì˜ ë¶„í• ëœ ì¡°ê°"""

    def __init__(self, doc_name: str, category: str, heading: str, text: str, index: int):
        self.doc_name = doc_name
        self.category = category
        self.heading = heading     # í•´ë‹¹ ì²­í¬ì˜ ì œëª©/í—¤ë”©
        self.text = text           # ì²­í¬ ë³¸ë¬¸
        self.index = index         # ì²­í¬ ìˆœì„œ
        self.score: float = 0.0    # ê²€ìƒ‰ ì ìˆ˜


# â”€â”€ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (íŒŒì¼ëª… â†’ ì¹´í…Œê³ ë¦¬) â”€â”€
CATEGORY_MAP = {
    "ì§€ë¦¬": "ì§€ë¦¬/ì§€ì—­",
    "ê°ì”": "ì§€ë¦¬/ê°ì”",
    "ì´ë™": "ì§€ë¦¬/ì´ë™",
    "ìŒì‹": "ìƒí™œ/ìŒì‹Â·ê±´ì¶•",
    "ê±´ì¶•": "ìƒí™œ/ìŒì‹Â·ê±´ì¶•",
    "ì˜ë³µ": "ìƒí™œ/ì˜ë³µ",
    "ë³µì‹": "ìƒí™œ/ì˜ë³µ",
    "ë¬´ê³µ": "ë¬´ê³µ/ì „íˆ¬",
    "ë¬´ê¸°": "ë¬´ê³µ/ë³‘ê¸°",
    "ë³‘ê¸°": "ë¬´ê³µ/ë³‘ê¸°",
    "ìºë¦­í„°": "ì¸ë¬¼",
    "ì¸ëª…ë¡": "ì¸ë¬¼",
    "ì„±ì¥í‘œ": "ì¸ë¬¼/ì„±ì¥",
    "ì„¸ë ¥ë„": "ì„¸ë ¥/ì¡°ì§",
    "ì¡°ì§ë„": "ì„¸ë ¥/ì¡°ì§",
    "ê²½ì˜": "ê²½ì˜/ìš©ì–´",
    "ë¬´í˜‘": "ë¬´í˜‘/ìš©ì–´",
    "ë¡œë“œë§µ": "ìŠ¤í† ë¦¬/ë¡œë“œë§µ",
    "ì¶œì—°ì": "ìŠ¤í† ë¦¬/ì¶œì—°ì",
    "ë£¨íŠ¸ë§µ": "ìŠ¤í† ë¦¬/ë£¨íŠ¸ë§µ",
    "6í•˜ì›ì¹™": "í…œí”Œë¦¿/ì„¤ê³„",
    "ìŠ¤ì¼ˆë ˆí†¤": "í…œí”Œë¦¿/ë¼ˆëŒ€",
}


def _guess_category(filename: str) -> str:
    """íŒŒì¼ëª…ì—ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ì¶”ë¡ í•©ë‹ˆë‹¤"""
    for keyword, category in CATEGORY_MAP.items():
        if keyword in filename:
            return category
    return "ê¸°íƒ€"


class RAGEngine:
    """
    ë¬´ë¦¼ ì„¸ê³„ê´€ RAG ê²€ìƒ‰ ì—”ì§„

    ì‚¬ìš©ë²•:
        engine = RAGEngine("../novels/murim_mna/world_db")
        engine.load()
        results = engine.search("í™”ì‚°íŒŒ", top_k=5)
    """

    def __init__(self, docs_path: str):
        self.docs_path = Path(docs_path)
        self.documents: list[Document] = []
        self.chunks: list[Chunk] = []
        self._loaded = False

    def load(self) -> int:
        """world_db í´ë”ì˜ ëª¨ë“  .md íŒŒì¼ì„ ë¡œë“œí•˜ê³  ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤"""
        self.documents = []
        self.chunks = []

        if not self.docs_path.exists():
            print(f"âš ï¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.docs_path}")
            return 0

        md_files = sorted(self.docs_path.glob("*.md"))
        print(f"ğŸ“‚ {len(md_files)}ê°œì˜ .md íŒŒì¼ ë°œê²¬")

        for md_file in md_files:
            try:
                content = md_file.read_text(encoding="utf-8")
                name = md_file.stem  # í™•ì¥ì ì œì™¸ íŒŒì¼ëª…
                category = _guess_category(name)

                doc = Document(
                    name=name,
                    category=category,
                    content=content,
                    path=str(md_file),
                )

                # ì²­í¬ ë¶„í• 
                doc_chunks = self._split_into_chunks(doc)
                doc.chunks = doc_chunks
                self.documents.append(doc)
                self.chunks.extend(doc_chunks)

                print(f"  âœ… {name} ({category}) â†’ {len(doc_chunks)}ê°œ ì²­í¬")

            except Exception as e:
                print(f"  âŒ {md_file.name} ë¡œë“œ ì‹¤íŒ¨: {e}")

        self._loaded = True
        print(f"\nğŸ“Š ì´ {len(self.documents)}ê°œ ë¬¸ì„œ, {len(self.chunks)}ê°œ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
        return len(self.chunks)

    def _split_into_chunks(self, doc: Document) -> list[Chunk]:
        """
        ë§ˆí¬ë‹¤ìš´ ë¬¸ì„œë¥¼ í—¤ë”©(##, ###) ê¸°ì¤€ìœ¼ë¡œ ì²­í¬ ë¶„í• í•©ë‹ˆë‹¤.
        í…Œì´ë¸”, ì½”ë“œë¸”ë¡ë„ í¬í•¨í•˜ì—¬ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
        """
        chunks: list[Chunk] = []
        content = doc.content

        # â”€â”€ ## ë˜ëŠ” ### ê¸°ì¤€ìœ¼ë¡œ ì„¹ì…˜ ë¶„ë¦¬ â”€â”€
        sections = re.split(r'\n(?=##\s)', content)

        for idx, section in enumerate(sections):
            section = section.strip()
            if not section or len(section) < 10:
                continue

            # í—¤ë”© ì¶”ì¶œ
            heading_match = re.match(r'^(#{1,4})\s+(.+)', section)
            heading = heading_match.group(2).strip() if heading_match else f"ì„¹ì…˜ {idx + 1}"

            # ì²­í¬ê°€ ë„ˆë¬´ í¬ë©´ ë” ë¶„í•  (1500ì ì´ˆê³¼ ì‹œ)
            if len(section) > 1500:
                sub_sections = re.split(r'\n(?=###\s)', section)
                for sub_idx, sub in enumerate(sub_sections):
                    sub = sub.strip()
                    if len(sub) < 10:
                        continue
                    sub_heading_match = re.match(r'^(#{1,4})\s+(.+)', sub)
                    sub_heading = sub_heading_match.group(2).strip() if sub_heading_match else heading

                    chunks.append(Chunk(
                        doc_name=doc.name,
                        category=doc.category,
                        heading=sub_heading,
                        text=sub,
                        index=len(chunks),
                    ))
            else:
                chunks.append(Chunk(
                    doc_name=doc.name,
                    category=doc.category,
                    heading=heading,
                    text=section,
                    index=len(chunks),
                ))

        return chunks

    def search(
        self,
        query: str,
        top_k: int = 5,
        category: Optional[str] = None,
        doc_name: Optional[str] = None,
    ) -> list[dict]:
        """
        í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            query: ê²€ìƒ‰ì–´ (ì˜ˆ: "í™”ì‚°íŒŒ ìœ„ì¹˜", "ìš”ë¦¬ ë©”ë‰´")
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            category: ì¹´í…Œê³ ë¦¬ í•„í„° (ì˜ˆ: "ì§€ë¦¬/ì§€ì—­")
            doc_name: íŠ¹ì • ë¬¸ì„œëª… í•„í„° (ì˜ˆ: "ì§€ë¦¬_ìƒì„¸")

        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ)
        """
        if not self._loaded:
            self.load()

        # ê²€ìƒ‰ì–´ ì •ê·œí™”
        query_lower = query.lower().strip()
        query_words = set(re.findall(r'[\wê°€-í£]+', query_lower))

        if not query_words:
            return []

        results: list[dict] = []

        for chunk in self.chunks:
            # â”€â”€ í•„í„° ì ìš© â”€â”€
            if category and category not in chunk.category:
                continue
            if doc_name and doc_name not in chunk.doc_name:
                continue

            # â”€â”€ ì ìˆ˜ ê³„ì‚° (TF ê¸°ë°˜ + ìœ„ì¹˜ ê°€ì¤‘ì¹˜) â”€â”€
            text_lower = chunk.text.lower()
            heading_lower = chunk.heading.lower()
            score = 0.0

            for word in query_words:
                # ë³¸ë¬¸ ë§¤ì¹­ (ê¸°ë³¸ 1ì )
                word_count = text_lower.count(word)
                if word_count > 0:
                    score += min(word_count, 5)  # ìµœëŒ€ 5ì  (ë°˜ë³µ íŒ¨ë„í‹°)

                # í—¤ë”© ë§¤ì¹­ (ê°€ì¤‘ì¹˜ 3ë°°)
                if word in heading_lower:
                    score += 3.0

                # ë¬¸ì„œëª… ë§¤ì¹­ (ê°€ì¤‘ì¹˜ 2ë°°)
                if word in chunk.doc_name.lower():
                    score += 2.0

            # â”€â”€ ì „ì²´ êµ¬ë¬¸ ë§¤ì¹­ ë³´ë„ˆìŠ¤ â”€â”€
            if query_lower in text_lower:
                score += 5.0

            if score > 0:
                results.append({
                    "doc_name": chunk.doc_name,
                    "category": chunk.category,
                    "heading": chunk.heading,
                    "text": chunk.text[:800],  # 800ì ì œí•œ
                    "score": round(score, 2),
                    "full_length": len(chunk.text),
                })

        # â”€â”€ ì ìˆ˜ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ â”€â”€
        results.sort(key=lambda x: x["score"], reverse=True)
        return results[:top_k]

    def search_by_tag(self, tag: str) -> list[dict]:
        """
        @íƒœê·¸ ê²€ìƒ‰ (ì˜ˆ: @ìš”ë¦¬, @ë¬´ê³µ, @ê°ì”)
        íƒœê·¸ì— ë§¤í•‘ëœ ì¹´í…Œê³ ë¦¬ì—ì„œ í•µì‹¬ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        tag = tag.lstrip("@").strip()

        # íƒœê·¸ â†’ ê²€ìƒ‰ ë§¤í•‘
        TAG_MAP = {
            "ìš”ë¦¬": {"query": "ìš”ë¦¬ ìŒì‹ ë©”ë‰´", "category": "ìƒí™œ/ìŒì‹Â·ê±´ì¶•"},
            "ìŒì‹": {"query": "ìš”ë¦¬ ìŒì‹ ë©”ë‰´", "category": "ìƒí™œ/ìŒì‹Â·ê±´ì¶•"},
            "ê±´ì¶•": {"query": "ê±´ì¶• ê°ì” êµ¬ì¡°", "category": "ìƒí™œ/ìŒì‹Â·ê±´ì¶•"},
            "ê°ì”": {"query": "ê°ì” ì£¼ë§‰", "category": "ì§€ë¦¬/ê°ì”"},
            "ë¬´ê³µ": {"query": "ë¬´ê³µ ì‹¬ë²• ì´ˆì‹", "category": "ë¬´ê³µ/ì „íˆ¬"},
            "ë¬´ê¸°": {"query": "ë¬´ê¸° ë³‘ê¸° ê²€", "category": "ë¬´ê³µ/ë³‘ê¸°"},
            "ë³‘ê¸°": {"query": "ë¬´ê¸° ë³‘ê¸° ê²€", "category": "ë¬´ê³µ/ë³‘ê¸°"},
            "ì˜ë³µ": {"query": "ì˜ë³µ ë³µì‹ ì˜ìƒ", "category": "ìƒí™œ/ì˜ë³µ"},
            "ì§€ë¦¬": {"query": "ì§€ì—­ ë„ì‹œ ì‚°", "category": "ì§€ë¦¬/ì§€ì—­"},
            "ì´ë™": {"query": "ì´ë™ ê²½ë¡œ ê±°ë¦¬", "category": "ì§€ë¦¬/ì´ë™"},
            "ì„¸ë ¥": {"query": "ì„¸ë ¥ ë¬¸íŒŒ ì¡°ì§", "category": "ì„¸ë ¥/ì¡°ì§"},
            "ì¡°ì§": {"query": "ì„¸ë ¥ ë¬¸íŒŒ ì¡°ì§", "category": "ì„¸ë ¥/ì¡°ì§"},
            "ì¸ë¬¼": {"query": "ìºë¦­í„° ì¸ë¬¼", "category": "ì¸ë¬¼"},
            "ìºë¦­í„°": {"query": "ìºë¦­í„° ì¸ë¬¼", "category": "ì¸ë¬¼"},
            "ê²½ì˜": {"query": "ê²½ì˜ M&A ì¬ë¬´", "category": "ê²½ì˜/ìš©ì–´"},
            "ë¡œë“œë§µ": {"query": "ë¡œë“œë§µ 300í™”", "category": "ìŠ¤í† ë¦¬/ë¡œë“œë§µ"},
        }

        if tag in TAG_MAP:
            mapped = TAG_MAP[tag]
            return self.search(mapped["query"], top_k=10, category=mapped["category"])
        else:
            # ë§¤í•‘ ì—†ìœ¼ë©´ ì¼ë°˜ ê²€ìƒ‰
            return self.search(tag, top_k=10)

    def get_categories(self) -> list[dict]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ ëª©ë¡ê³¼ ë¬¸ì„œ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        cat_map: dict[str, int] = {}
        for doc in self.documents:
            cat_map[doc.category] = cat_map.get(doc.category, 0) + 1

        return [
            {"category": cat, "count": count}
            for cat, count in sorted(cat_map.items())
        ]

    def get_document(self, name: str) -> Optional[dict]:
        """íŠ¹ì • ë¬¸ì„œì˜ ì „ì²´ ë‚´ìš©ì„ ë°˜í™˜í•©ë‹ˆë‹¤"""
        for doc in self.documents:
            if doc.name == name or name in doc.name:
                return {
                    "name": doc.name,
                    "category": doc.category,
                    "content": doc.content,
                    "chunk_count": len(doc.chunks),
                    "char_count": len(doc.content),
                }
        return None

    def get_all_documents(self) -> list[dict]:
        """ì „ì²´ ë¬¸ì„œ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤ (ë‚´ìš© ë¯¸í¬í•¨)"""
        return [
            {
                "name": doc.name,
                "category": doc.category,
                "chunk_count": len(doc.chunks),
                "char_count": len(doc.content),
            }
            for doc in self.documents
        ]

    def get_stats(self) -> dict:
        """ì—”ì§„ í†µê³„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤"""
        total_chars = sum(len(doc.content) for doc in self.documents)
        return {
            "documents": len(self.documents),
            "chunks": len(self.chunks),
            "total_chars": total_chars,
            "categories": len(set(doc.category for doc in self.documents)),
            "loaded": self._loaded,
        }
